---
title: "GNU Make for Reproducible Research"
subtitle: "Automating and Documenting Data Analysis Pipelines"
author: "UBC BIOF Statistics Workshop"
format:
  revealjs:
    theme: simple
    slide-number: true
    transition: slide
#    navigation-mode: linear
    embed-resources: true
    width: 1280
    height: 720
    controls: true
    progress: true
    code-line-numbers: false
    output-file: index.html # If naming other files , gh complains
engine: knitr
knitr:
  opts_chunk:
    eval: false
bibliography: references.bib
---

## Objective

**Today's Goal:**

Learn how to use GNU Make to automate your research workflows

. . .

**What you'll learn:**

- Why Make > single, gigantic R script
- Basic Make syntax
- Real data analysis example



## An example of our typical code workflow

Rather than running 1 gigantic R script, we were smart enough to run smaller scripts of it

```{r}
#| echo: true
#| eval: false
#| code-overflow: scroll
#| code-summary: "my_full_experiment_version2.R"
#| code-fold: true
#| code-line-numbers: true

suppressPackageStartupMessages(library(dplyr))
library(readr)
library(broom)
library(ggplot2)
library(patchwork)

# Download data from internet
dest <- "data/iris.csv"
url <- "https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv"
download.file(url, dest, quiet = FALSE)

# Read raw data
iris_clean <- read_csv("data/iris.csv", show_col_types = FALSE)

# Clean the data
iris_clean <- iris_clean %>%
  tidyr::drop_na() %>%                     # Remove rows with missing values
  rename_with(tolower) %>%          # Standardize column names to lowercase
  mutate(id = row_number())         # Add a unique ID column

# Write cleaned data
#write_csv(iris_clean, "data/iris_clean.csv")

cat("Data cleaning complete!\n")
cat(sprintf("  Original rows: %d\n", nrow(iris_clean)))
cat(sprintf("  Cleaned rows: %d\n", nrow(iris_clean)))


# Read cleaned data
#iris_clean <- read_csv("data/iris_clean.csv")

# 1. Summary statistics by species
summary_stats <- iris_clean %>%
  group_by(species) %>%
  summarise(
    across(c(sepal_length, sepal_width, petal_length, petal_width),
           list(mean = mean, sd = sd),
           .names = "{.col}_{.fn}")
  )

# 2. Fit a simple linear model
model <- lm(sepal_length ~ petal_length + species, data = iris_clean)
model_tidy <- tidy(model)
model_glance <- glance(model)

# Create output file
sink("results/model_summary.txt")

cat(strrep("=", 60), "\n")
cat("IRIS DATASET ANALYSIS\n")
cat(strrep("=", 60), "\n\n")

cat("Summary Statistics by Species:\n")
cat(strrep("-", 60), "\n")
print(summary_stats)

cat("\n\nLinear Model Results:\n")
cat(strrep("-", 60), "\n")
cat("Model: sepal_length ~ petal_length + species\n\n")
print(model_tidy)

cat("\nModel Fit Statistics:\n")
print(model_glance)

cat("\n", strrep("=", 60), "\n")
cat("Analysis complete!\n")

sink()

cat("Analysis results saved to results/model_summary.txt\n")

# Read cleaned data
#iris_clean <- read_csv("data/iris_clean.csv", show_col_types = FALSE)



# Plot 1: Sepal Length vs Petal Length
p1 <- ggplot(iris_clean, aes(x = petal_length, y = sepal_length, color = species)) +
  geom_point(size = 3) +
  labs(
    x = "Petal Length (cm)",
    y = "Sepal Length (cm)",
    title = "Sepal vs Petal Length"
  ) +
  theme_minimal()

# Plot 2: Sepal Width vs Petal Width
p2 <- ggplot(iris_clean, aes(x = petal_width, y = sepal_width, color = species)) +
  geom_point(size = 3) +
  labs(
    x = "Petal Width (cm)",
    y = "Sepal Width (cm)",
    title = "Sepal vs Petal Width"
  ) +
  theme_minimal()

# Plot 3: Distribution of Sepal Length by Species
p3 <- ggplot(iris_clean, aes(x = species, y = sepal_length, fill = species)) +
  geom_boxplot() +
  labs(
    x = "Species",
    y = "Sepal Length (cm)",
    title = "Sepal Length by Species"
  ) +
  scale_fill_manual(values = c("lightblue", "lightgreen", "lightcoral")) +
  theme_minimal() +
  theme(legend.position = "none")

# Plot 4: Distribution of Petal Length by Species
p4 <- ggplot(iris_clean, aes(x = species, y = petal_length, fill = species)) +
  geom_boxplot() +
  labs(
    x = "Species",
    y = "Petal Length (cm)",
    title = "Petal Length by Species"
  ) +
  scale_fill_manual(values = c("lightblue", "lightgreen", "lightcoral")) +
  theme_minimal() +
  theme(legend.position = "none")

# Save all plots in a 2x2 grid
joined_plot <- (p1 | p2) / (p3 | p4) +
  plot_layout(guides = "collect")  # Collect all legends into one


ggsave("figures/iris_plot.png", joined_plot, width = 12, height = 8, dpi = 150)

cat("Plot saved to figures/iris_plot.png\n")


```

. . .

**Problems:**

- What if I want to change my analysis
- What if one step fails halfway through?
- What order should I run?

. . .

‚úÖ **Decompose this to modular unit scripts**

## A better example of our typical code workflow

```{bash}
#| echo: true
#| eval: false
#| code-fold: false

# Step 1: Download data
Rscript download_data.R
# Step 2: Clean the data
Rscript clean_data.R
# Step 3: Run analysis
Rscript analyze.R
# Step 4: Make figures
Rscript make_figures.R
```

You run all four scripts now, Analysis complete! ‚úÖ 


## Then You Update Your Analysis Script...

- You realize you need to fix a bug in `analyze.R`

. . .

**Question: Which scripts need to be re-run?**

. . .

:::: {.segments}

::: {.column width="45%"}

1. Just `analyze.R`
2. Both `analyze.R` and `make_figures.R`
3. All four scripts?
4. Not sure..., better run them all!

:::

::: {.column width="10%"}
<!--- Purpose empty col for gap -->
:::


::: {.column width="45%"}



```{bash}
#| echo: true
#| eval: false
#| code-fold: false
# Step 1: Download data
Rscript download_data.R
# Step 2: Clean the data
Rscript clean_data.R
# Step 3: Run analysis
Rscript analyze.R
# Step 4: Make figures
Rscript make_figures.R
```

:::


::::


## New slide


- What if I want to add more analysis there?
- How do you know what order to run?
- What happens when you update the data?

. . .

‚ùå Re-run everything (slow!)

‚ùå Manually track what needs updating (error-prone!)

‚ùå Forget to update downstream files (wrong results!)

. . .

‚úÖ **Decompose this to modular unit, and pipe them up with GNU Make**

## What is GNU Make? 

:::: {.segments}

::: {.column width="82%"}
"GNU is not unix" [@stallman1998gnu], a build automation tool that:

1. Tracks dependencies between files
2. **Runs only what's needed** when files change
3. Documents your workflow in one place
4. **Ensures reproducibility**

:::

::: {.column width="18%"}

![](assets/gnu_make_logo.png)
:::

::::

. . .

Originally designed for compiling software, but perfect for data analysis!

::: {.notes}
- Make is language agnostic, so it can run any program compatible with a Unix shel

- Make is pretty steep. It‚Äôs frustrating to learn, and it can be tricky to use even after you‚Äôve learned the basics. 

- Make has no graphical user interface, so you need to have at least a basic familiarity with the Unix command line. You also have to know how to run scripts non-interactively. 
:::


## Basic Makefile Syntax

The tool itself is a binary called `make` thats runs with `Makefile`.

```makefile
target: dependencies
	command
```

. . .

**Example:**

```{makefile}
#| echo: true
#| eval: false
#| code-line-numbers: true
mean_normal_distribution.txt: sample_from_normal_distribution.R
  Rscript sample_from_normal_distribution.R
```

. . .

- `mean_normal_distribution.txt` = **target** (what you want to create)
- `sample_from_normal_distribution.R` = **dependency** (what you need)
- `Rscript sample_from_normal_distribution.R` = **command** (how to make it)

**‚ö†Ô∏è Important: Commands MUST start with a TAB, not spaces!**



## How Make Works

When you run `make mean_normal_distribution.txt`:

. . .

1. Check if the `mean_normal_distribution.txt` exists
2. Check if the  `sample_from_normal_distribution.R` is newer than `mean_normal_distribution.txt`
3. If yes ‚Üí run the command
4. If no ‚Üí skip (already up-to-date!)

. . .


**This is the magic! üé©‚ú®**

Make only rebuilds what's necessary based on file timestamps.

## Real World Usage 

![Adapted from https://www.evan-soil.io/blog/ode-to-gnu-make/](assets/example-dependency-graph.png)

- You want to track how you create every figure you used in your manuscript (`ideally`)
- You want to save time by re-running as little code as possible


## Real Example: Data Analysis Pipeline

```{r}
#| eval: false
#| echo: true
#| code-overflow: scroll 
#| code-fold: show
#| code-line-numbers: true

suppressPackageStartupMessages(library(dplyr))
library(readr)
library(broom)
library(ggplot2)
library(patchwork)


# Download data from internet
dest <- "data/iris.csv"
url <- "https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv"
download.file(url, dest, quiet = FALSE)

# Read raw data
iris_clean <- read_csv("data/iris.csv", show_col_types = FALSE)

# Clean the data
iris_clean <- iris_clean %>%
  tidyr::drop_na() %>%                     # Remove rows with missing values
  rename_with(tolower) %>%          # Standardize column names to lowercase
  mutate(id = row_number())         # Add a unique ID column

# Write cleaned data
#write_csv(iris_clean, "data/iris_clean.csv")

cat("Data cleaning complete!\n")
cat(sprintf("  Original rows: %d\n", nrow(iris_clean)))
cat(sprintf("  Cleaned rows: %d\n", nrow(iris_clean)))


# Read cleaned data
#iris_clean <- read_csv("data/iris_clean.csv")

# 1. Summary statistics by species
summary_stats <- iris_clean %>%
  group_by(species) %>%
  summarise(
    across(c(sepal_length, sepal_width, petal_length, petal_width),
           list(mean = mean, sd = sd),
           .names = "{.col}_{.fn}")
  )

# 2. Fit a simple linear model
model <- lm(sepal_length ~ petal_length + species, data = iris_clean)
model_tidy <- tidy(model)
model_glance <- glance(model)


# Create output file
sink("results/model_summary.txt")

cat(strrep("=", 60), "\n")
cat("IRIS DATASET ANALYSIS\n")
cat(strrep("=", 60), "\n\n")

cat("Summary Statistics by Species:\n")
cat(strrep("-", 60), "\n")
print(summary_stats)

cat("\n\nLinear Model Results:\n")
cat(strrep("-", 60), "\n")
cat("Model: sepal_length ~ petal_length + species\n\n")
print(model_tidy)

cat("\nModel Fit Statistics:\n")
print(model_glance)

cat("\n", strrep("=", 60), "\n")
cat("Analysis complete!\n")

sink()

cat("Analysis results saved to results/model_summary.txt\n")

# Read cleaned data
#iris_clean <- read_csv("data/iris_clean.csv", show_col_types = FALSE)



# Plot 1: Sepal Length vs Petal Length
p1 <- ggplot(iris_clean, aes(x = petal_length, y = sepal_length, color = species)) +
  geom_point(size = 3) +
  labs(
    x = "Petal Length (cm)",
    y = "Sepal Length (cm)",
    title = "Sepal vs Petal Length"
  ) +
  theme_minimal()

# Plot 2: Sepal Width vs Petal Width
p2 <- ggplot(iris_clean, aes(x = petal_width, y = sepal_width, color = species)) +
  geom_point(size = 3) +
  labs(
    x = "Petal Width (cm)",
    y = "Sepal Width (cm)",
    title = "Sepal vs Petal Width"
  ) +
  theme_minimal()

# Plot 3: Distribution of Sepal Length by Species
p3 <- ggplot(iris_clean, aes(x = species, y = sepal_length, fill = species)) +
  geom_boxplot() +
  labs(
    x = "Species",
    y = "Sepal Length (cm)",
    title = "Sepal Length by Species"
  ) +
  scale_fill_manual(values = c("lightblue", "lightgreen", "lightcoral")) +
  theme_minimal() +
  theme(legend.position = "none")

# Plot 4: Distribution of Petal Length by Species
p4 <- ggplot(iris_clean, aes(x = species, y = petal_length, fill = species)) +
  geom_boxplot() +
  labs(
    x = "Species",
    y = "Petal Length (cm)",
    title = "Petal Length by Species"
  ) +
  scale_fill_manual(values = c("lightblue", "lightgreen", "lightcoral")) +
  theme_minimal() +
  theme(legend.position = "none")

# Save all plots in a 2x2 grid
joined_plot <- (p1 | p2) / (p3 | p4) +
  plot_layout(guides = "collect")  # Collect all legends into one


ggsave("figures/iris_plot.png", joined_plot, width = 12, height = 8, dpi = 150)

cat("Plot saved to figures/iris_plot.png\n")



```

::: {.notes}

Suppose we have a big script that does everything for us: gather data, wrangling operations, fit stat model, and plot figures

- Hard to tell where exactly fails if anything happens
- Rerun from top to bottom NO MATTER WHAT
- **Pain** to review code

:::




## Real Example: Data Analysis Pipeline

Let's build a complete analysis pipeline step by step by moving code out from this big R script file.

. . .

**Our pipeline:**

1. Download data from the web
2. Clean and preprocess
3. Run statistical analysis
4. Generate figures
5. Create final report



## Step 1: Download Data

```{r}
#| code-fold: true
#| code-summary: "scripts/download_data.R"
#| echo: true

dest <- "data/iris.csv"
url <- "https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv"
download.file(url, dest, quiet = FALSE)
```

Open `Makefile` and add the corresponding target:

```makefile
data/iris.csv: scripts/download_data.R
  Rscript scripts/download_data.R
```

. . .

**Run it:**

```bash
make data/iris.csv
```

. . .

**Run again:**

```bash
make data/raw_data.csv
# make: 'data/raw_data.csv' is up to date.
```

---

## Step 2: Clean Data

**Add to `Makefile`:**

```makefile
data/clean_data.csv: data/raw_data.csv scripts/clean.R
	Rscript scripts/clean.R
```

. . .

**What this means:**

- To create `data/clean_data.csv`...
- You need `data/raw_data.csv` AND `scripts/clean.R`
- Run the R script to process it

. . .

**If you edit `clean.R`, Make knows to re-run this step!**


<!-- ## Step 3: Statistical Analysis -->

<!-- ```makefile -->
<!-- results/statistics.txt: data/clean_data.csv scripts/analyze.R -->
<!-- 	mkdir -p results -->
<!-- 	Rscript scripts/analyze.R -->
<!-- ``` -->

<!-- . . . -->

<!-- **Chain of dependencies:** -->

<!-- `raw_data.csv` ‚Üí `clean_data.csv` ‚Üí `statistics.txt` -->

<!-- . . . -->

<!-- Make automatically handles the chain! -->

<!-- --- -->

<!-- ## Step 4: Generate Figures -->

<!-- ```makefile -->
<!-- figures/plot1.png: results/statistics.txt scripts/plot.R -->
<!-- 	mkdir -p figures -->
<!-- 	Rscript scripts/plot.R -->
<!-- ``` -->

<!-- . . . -->

<!-- Now we have a full pipeline: -->

<!-- ``` -->
<!-- raw_data.csv ‚Üí clean_data.csv ‚Üí statistics.txt ‚Üí plot1.png -->
<!-- ``` -->

<!-- --- -->

<!-- ## Complete Makefile Example -->

<!-- ```makefile -->
<!-- # Download data -->
<!-- data/raw_data.csv: -->
<!-- 	mkdir -p data -->
<!-- 	wget -O data/raw_data.csv https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv -->

<!-- # Clean data -->
<!-- data/clean_data.csv: data/raw_data.csv scripts/clean.R -->
<!-- 	Rscript scripts/clean.R -->

<!-- # Analyze -->
<!-- results/statistics.txt: data/clean_data.csv scripts/analyze.R -->
<!-- 	mkdir -p results -->
<!-- 	Rscript scripts/analyze.R -->

<!-- # Plot -->
<!-- figures/plot1.png: results/statistics.txt scripts/plot.R -->
<!-- 	mkdir -p figures -->
<!-- 	Rscript scripts/plot.R -->
<!-- ``` -->

<!-- --- -->

<!-- ## Running Your Pipeline -->

<!-- **Run the entire pipeline:** -->

<!-- ```bash -->
<!-- make figures/plot1.png -->
<!-- ``` -->

<!-- . . . -->

<!-- Make will: -->

<!-- 1. Check if `data/raw_data.csv` exists ‚Üí download if needed -->
<!-- 2. Check if `data/clean_data.csv` is up-to-date ‚Üí clean if needed -->
<!-- 3. Check if `results/statistics.txt` is up-to-date ‚Üí analyze if needed -->
<!-- 4. Check if `figures/plot1.png` is up-to-date ‚Üí plot if needed -->

<!-- . . . -->

<!-- **Only runs what's necessary!** -->

<!-- --- -->

<!-- ## Phony Targets -->

<!-- Some targets don't create files: -->

<!-- ```makefile -->
<!-- .PHONY: clean all -->

<!-- all: figures/plot1.png -->

<!-- clean: -->
<!-- 	rm -f data/clean_data.csv -->
<!-- 	rm -f results/statistics.txt -->
<!-- 	rm -f figures/plot1.png -->
<!-- ``` -->

<!-- . . . -->

<!-- **Usage:** -->

<!-- ```bash -->
<!-- make all    # Build everything -->
<!-- make clean  # Remove generated files -->
<!-- ``` -->

<!-- --- -->

<!-- ## Sometimes convenience target -->

<!-- Sometimes, you just want to have everything to send out to your collaborators -->

<!-- ```makefile -->
<!-- collaboration-packet.zip: data-wrangling.R raw-data.csv paper.Rmd comments.txt -->
<!--     Rscript data-wrangling.R  clean-data.csv -->
<!--     gzip collaboration-packet.zip clean-data.csv paper.Rmd comments.txt -->
<!-- ``` -->

<!-- ## Variables for Cleaner Makefiles -->

<!-- ```makefile -->
<!-- # Define variables -->
<!-- R = Rscript -->
<!-- DATA_DIR = data -->
<!-- RESULTS_DIR = results -->
<!-- FIGURES_DIR = figures -->

<!-- # Use variables -->
<!-- $(DATA_DIR)/clean_data.csv: $(DATA_DIR)/raw_data.csv scripts/clean.R -->
<!-- 	$(R) scripts/clean.R -->

<!-- $(FIGURES_DIR)/plot1.png: $(RESULTS_DIR)/statistics.txt scripts/plot.R -->
<!-- 	mkdir -p $(FIGURES_DIR) -->
<!-- 	$(R) scripts/plot.R -->
<!-- ``` -->

<!-- . . . -->

<!-- **Benefits:** Easy to change paths or commands in one place! -->

<!-- --- -->

<!-- ## Pattern Rules -->

<!-- For repetitive tasks: -->

<!-- ```makefile -->
<!-- # Convert all .csv files to .xlsx -->
<!-- %.xlsx: %.csv -->
<!-- 	python convert_to_excel.py $< $@ -->
<!-- ``` -->

<!-- . . . -->

<!-- **Special variables:** -->

<!-- - `$<` = first dependency (`%.csv`) -->
<!-- - `$@` = target (`%.xlsx`) -->

<!-- . . . -->

<!-- This rule works for ANY csv ‚Üí xlsx conversion! -->

<!-- --- -->

<!-- ## Real-World Example: Complete Pipeline -->

<!-- ```makefile -->
<!-- .PHONY: all clean -->

<!-- # Variables -->
<!-- R = Rscript -->
<!-- DATA = data/iris.csv -->
<!-- CLEAN_DATA = data/iris_clean.csv -->
<!-- RESULTS = results/model_summary.txt -->
<!-- FIGURE = figures/iris_plot.png -->

<!-- # Default target -->
<!-- all: $(FIGURE) -->

<!-- # Pipeline -->
<!-- $(DATA): -->
<!-- 	mkdir -p data -->
<!-- 	wget -O $(DATA) \ -->
<!-- 	  https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv -->

<!-- $(CLEAN_DATA): $(DATA) scripts/clean.R -->
<!-- 	$(R) scripts/clean.R -->

<!-- $(RESULTS): $(CLEAN_DATA) scripts/analyze.R -->
<!-- 	mkdir -p results -->
<!-- 	$(R) scripts/analyze.R -->

<!-- $(FIGURE): $(RESULTS) scripts/plot.R -->
<!-- 	mkdir -p figures -->
<!-- 	$(R) scripts/plot.R -->

<!-- # Clean up -->
<!-- clean: -->
<!-- 	rm -rf data results figures -->
<!-- ``` -->

<!-- --- -->

<!-- ## Parallel Execution -->

<!-- Make can run independent tasks simultaneously: -->

<!-- ```makefile -->
<!-- all: figure1.png figure2.png figure3.png -->

<!-- figure1.png: data.csv script1.R -->
<!-- 	Rscript script1.R -->

<!-- figure2.png: data.csv script2.R -->
<!-- 	Rscript script2.R -->

<!-- figure3.png: data.csv script3.R -->
<!-- 	Rscript script3.R -->
<!-- ``` -->

<!-- **Run in parallel:** -->

<!-- ```bash -->
<!-- make -j 3 all  # Run 3 jobs simultaneously -->
<!-- ``` -->

<!-- --- -->

<!-- ## When to Use Make vs R Scripts -->

<!-- **Use Make when:** -->

<!-- - Multiple steps in your pipeline -->
<!-- - Different tools (R, Python, bash) -->
<!-- - Long-running computations -->
<!-- - Need to track dependencies -->

<!-- . . . -->

<!-- **Stick with R scripts when:** -->

<!-- - Everything fits in one R script -->
<!-- - Very simple analysis -->
<!-- - No intermediate files -->

<!-- --- -->

<!-- ## Best Practices -->

<!-- 1. **One Makefile per project** in the root directory -->
<!-- 2. **Use meaningful target names** (not `temp1.csv`) -->
<!-- 3. **Comment your Makefile** to explain steps -->
<!-- 4. **Use variables** for paths and commands -->
<!-- 5. **Add `.PHONY`** for non-file targets -->
<!-- 6. **Test incrementally** as you build your Makefile -->

<!-- --- -->

<!-- ## Common Pitfalls -->

<!-- ‚ùå **Using spaces instead of tabs** -->

<!-- ```makefile -->
<!-- target: dependency -->
<!--     command  # WRONG! This is spaces -->
<!-- 	command  # RIGHT! This is a tab -->
<!-- ``` -->

<!-- . . . -->

<!-- ‚ùå **Circular dependencies** -->

<!-- ```makefile -->
<!-- a.txt: b.txt -->
<!-- 	cat b.txt > a.txt -->

<!-- b.txt: a.txt  # CIRCULAR! -->
<!-- 	cat a.txt > b.txt -->
<!-- ``` -->

<!-- --- -->

<!-- ## Debugging Tips -->

<!-- **Check what Make would do:** -->

<!-- ```bash -->
<!-- make -n target  # Dry run, shows commands without executing -->
<!-- ``` -->

<!-- . . . -->

<!-- **See why Make rebuilds:** -->

<!-- ```bash -->
<!-- make -d target  # Debug mode, verbose output -->
<!-- ``` -->

<!-- . . . -->

<!-- **Force rebuild:** -->

<!-- ```bash -->
<!-- make -B target  # Rebuild regardless of timestamps -->
<!-- ``` -->

<!-- --- -->

<!-- ## Example: Why Make > Shell Script -->

<!-- **Shell script approach:** -->

<!-- ```bash -->
<!-- #!/bin/bash -->
<!-- Rscript download.R     # Always runs (even if data unchanged) -->
<!-- Rscript clean.R        # Always runs -->
<!-- Rscript analyze.R      # Always runs -->
<!-- Rscript plot.R         # Always runs -->
<!-- # Takes 30 minutes every time! -->
<!-- ``` -->

<!-- . . . -->

<!-- **Makefile approach:** -->

<!-- ```bash -->
<!-- make all -->
<!-- # First run: 30 minutes -->
<!-- # Edit plot.R and re-run: 10 seconds (only reruns plotting!) -->
<!-- # No changes: instant (nothing to do!) -->
<!-- ``` -->

<!-- --- -->

<!-- ## Hands-On Exercise (Optional) -->

<!-- **Try this yourself:** -->

<!-- 1. Create a simple `Makefile` -->
<!-- 2. Add a target that creates a text file -->
<!-- 3. Add a target that depends on that file -->
<!-- 4. Run `make` and observe behavior -->
<!-- 5. Touch a file and run `make` again -->

<!-- **Example starter:** -->

<!-- ```makefile -->
<!-- hello.txt: -->
<!-- 	echo "Hello, Make!" > hello.txt -->

<!-- goodbye.txt: hello.txt -->
<!-- 	cat hello.txt | sed 's/Hello/Goodbye/' > goodbye.txt -->
<!-- ``` -->

<!-- --- -->

<!-- ## Advanced Topics (For Later) -->

<!-- Once comfortable with basics: -->

<!-- - **Automatic variables** (`$@`, `$<`, `$^`) -->
<!-- - **Functions** (`wildcard`, `patsubst`) -->
<!-- - **Conditional execution** (`ifeq`, `ifdef`) -->
<!-- - **Including other Makefiles** -->
<!-- - **Integration with version control** -->
<!-- - **Make for reports** (Quarto, R Markdown) -->

<!-- --- -->

<!-- ## Resources -->

<!-- **Documentation:** -->

<!-- - GNU Make Manual: <https://www.gnu.org/software/make/manual/> -->
<!-- - Make for reproducible research: <https://makefiletutorial.com/> -->

<!-- . . . -->

<!-- **Tutorials:** -->

<!-- - Software Carpentry: Make for Data Analysis -->
<!-- - Minimal Make by Karl Broman -->

<!-- . . . -->

<!-- **Getting Help:** -->

<!-- - `man make` (in terminal) -->
<!-- - Stack Overflow: `[makefile]` tag -->

<!-- --- -->

<!-- ## Key Takeaways -->

<!-- ‚úÖ **Make tracks dependencies** between files -->

<!-- . . . -->

<!-- ‚úÖ **Only rebuilds what's necessary** (saves time!) -->

<!-- . . . -->

<!-- ‚úÖ **Documents your workflow** in one place -->

<!-- . . . -->

<!-- ‚úÖ **Works with any tools** (R, Python, bash, etc.) -->

<!-- . . . -->

<!-- ‚úÖ **Essential for reproducible research** -->

<!-- --- -->

<!-- ## Your Next Steps -->

<!-- 1. **Start small**: Convert one script to a Makefile -->
<!-- 2. **Build incrementally**: Add one target at a time -->
<!-- 3. **Test often**: Run `make` frequently -->
<!-- 4. **Read the manual**: When you need advanced features -->
<!-- 5. **Share your Makefiles**: Help others reproduce your work! -->

<!-- --- -->

<!-- ## Questions? ü§î -->

<!-- **Thank you for attending!** -->

<!-- Remember: Reproducible research benefits everyone! -->

<!-- . . . -->

<!-- **Makefile = Your research lab notebook** üìì -->

<!-- . . . -->

<!-- Start using Make in your next project! üöÄ -->


<!-- ## Make vs Shell Scripts -->

<!-- **Makefile approach:** -->

<!-- ```makefile -->
<!-- results.csv: raw_data.csv clean.R -->
<!-- 	Rscript clean.R -->

<!-- plots/figure1.png: results.csv plot.R -->
<!-- 	Rscript plot.R -->
<!-- ``` -->

<!-- **Benefits:** -->

<!-- - Only re-runs when inputs change -->
<!-- - Automatic dependency resolution -->
<!-- - Self-documenting workflow -->
<!-- - Can run independent tasks in parallel -->



<!-- ## Make vs Shell Scripts -->

<!-- **Shell script approach:** -->

<!-- ```bash -->
<!-- #!/bin/bash -->
<!-- # run_all.sh -->
<!-- Rscript download.R -->
<!-- Rscript clean.R -->
<!-- Rscript analyze.R -->
<!-- Rscript plot.R -->
<!-- ``` -->

<!-- **Limitations:** -->

<!-- - Runs everything every time -->
<!-- - No dependency tracking -->
<!-- - Manual ordering -->
<!-- - No parallelization -->






<!-- ## Optional: Installing GNU Make on Windows  -->

<!-- **Option 1: Using Chocolatey (Recommended)** -->

<!-- 1. **Install Chocolatey** (if not already installed): -->
<!--    - Right-click Start menu ‚Üí "Windows PowerShell (Admin)" -->
<!--    - Visit: <https://chocolatey.org/install> -->
<!--    - Copy and run the installation command from the website -->

<!-- 2. **Install GNU Make:** -->
<!--    ```powershell -->
<!--    choco install make -->
<!--    ``` -->

<!-- 3. **Verify installation:** -->
<!--    ```bash -->
<!--    make --version -->
<!--    # Should show: GNU Make 4.x -->
<!--    ``` -->

<!-- . . . -->

<!-- **Option 2: Using Git for Windows (Built-in)** -->

<!-- - Download and install **Git for Windows**: <https://gitforwindows.org/> -->
<!-- - Make is included! Access via **Git Bash** terminal -->
<!-- - Look for "Git Bash" in your Start menu -->

<!-- . . . -->

<!-- **Troubleshooting:** -->
<!-- - If `make` command not found ‚Üí Restart terminal/PowerShell -->
<!-- - Use Git Bash instead of Command Prompt for Option 2 -->

<!-- ## Optional: Installing GNU Make on macOS -->

<!-- **Option 1: Using Homebrew (Recommended)** -->

<!-- 1. **Install Homebrew** (if not already installed): -->
<!--    - Open **Terminal** (Applications ‚Üí Utilities ‚Üí Terminal) -->
<!--    - Visit: <https://brew.sh/> -->
<!--    - Copy and run the installation command: -->
<!--    ```bash -->
<!--    /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)" -->
<!--    ``` -->

<!-- 2. **Install GNU Make:** -->
<!--    ```bash -->
<!--    brew install make -->
<!--    ``` -->

<!-- 3. **Verify installation:** -->
<!--    ```bash -->
<!--    make --version -->
<!--    # Should show: GNU Make 4.x -->
<!--    ``` -->

<!-- . . . -->

<!-- **Option 2: Xcode Command Line Tools (Built-in)** -->

<!-- GNU Make comes with Xcode Command Line Tools: -->
<!-- ```bash -->
<!-- xcode-select --install -->
<!-- ``` -->
<!-- Click "Install" in the popup window -->

<!-- . . . -->

<!-- **Troubleshooting:** -->
<!-- - If `make --version` shows older version ‚Üí Use `brew install make` -->
<!-- - Homebrew installs as `gmake` on some systems ‚Üí Create alias or use `gmake` -->
